---
title: "Linear Models with R - Exercises"
author: "Rachel Greenlee"
date: "8/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('faraway')
library('ggplot2')
library('ggExtra')
library('skimr')
library('tidyverse')
```


#Linear Models w/ R Chapter 1


## Exercise 1.1
The dataset teengamb concerns a study of teenage gambling in Britain. Make a
numerical and graphical summary of the data, commenting on any features that
you find interesting. Limit the output you present to a quantity that a busy reader
would find sufficient to get a basic understanding of the data.


```{r}
head(teengamb)
summary(teengamb)
```


```{r}
p1 <- ggplot(teengamb, aes(x = status, y = gamble)) +
  geom_point() +
  labs(title = "Socioeconomic Status by Gambling Expenditures/Year")

ggExtra::ggMarginal(p1, type = "histogram")

```

```{r}
teengamb$sex <- as.factor(teengamb$sex)

ggplot(teengamb, aes(x = sex, y = gamble)) +
  geom_boxplot() +
  labs(title = "Teenager's Sex by Expendirues on Gambling Per Year",
       subtitle = "0 = male, 1 = female")
  
```

```{r}
ggplot(teengamb, aes(x = verbal, y = gamble)) +
  geom_point() +
  labs(title = "Teenager's Verbal Score by Expenditures on Gambling per Year",
       subtitle = "where verbal score = count words out of 12 correctly defined")
```




## Exercise 1.3
The dataset prostate is from a study on 97 men with prostate cancer who were
due to receive a radical prostatectomy. Make a numerical and graphical summary
of the data as in the first question.


```{r}
head(prostate)
summary(prostate)
```





## Exercise 1.4
The dataset sat comes from a study entitled “Getting What You Pay For: The Debate Over Equity in Public School Expenditures.” Make a numerical and graphical
summary of the data as in the first question


```{r}
head(sat)
summary(sat)
```




## Exercise 1.5
The dataset divusa contains data on divorces in the United States from 1920 to
1996. Make a numerical and graphical summary of the data as in the first question.

```{r}
head(divusa)
summary(divusa)
```




#Linear Models w/ R Chapter 2

## Exercise 2.4
The dataset prostate comes from a study on 97 men with prostate cancer who
were due to receive a radical prostatectomy. Fit a model with lpsa as the response
and lcavol as the predictor. Record the residual standard error and the R2. Now
add lweight, svi, lbph, age, lcp, pgg45 and gleason to the model one at a
time. For each model record the residual standard error and the R2. Plot the
trends in these two statistics.

```{r}
# view data summary and pull up help file with variable definitions
summary(prostate)
```


```{r}
# always plot variables before running regression
ggplot(prostate, aes(x = lcavol, y = lpsa)) +
  geom_point()
```


```{r}
# run base regression

lm1 <- lm(lpsa ~ 
            lcavol, data = prostate)
#summary(lm1)

df24 <- data.frame("adjR" = summary(lm1)$adj.r.squared, "residSE" = summary(lm1)$sigma)

# adding one variable at a time & storing adjR and residSE
lm2 <- lm(lpsa ~ 
            lcavol +
            lweight, data = prostate)
df24 <- rbind(df24, list(summary(lm2)$adj.r.squared, summary(lm2)$sigma))


lm3 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi, data = prostate)
df24 <- rbind(df24, list(summary(lm3)$adj.r.squared, summary(lm3)$sigma))


lm4 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi +
            lbph, data = prostate)
df24 <- rbind(df24, list(summary(lm4)$adj.r.squared, summary(lm4)$sigma))


lm5 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi +
            lbph +
            age, data = prostate)
df24 <- rbind(df24, list(summary(lm5)$adj.r.squared, summary(lm5)$sigma))


lm6 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi +
            lbph +
            age +
            lcp, data = prostate)
df24 <- rbind(df24, list(summary(lm6)$adj.r.squared, summary(lm6)$sigma))


lm7 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi +
            lbph +
            age +
            lcp +
            pgg45, data = prostate)
df24 <- rbind(df24, list(summary(lm7)$adj.r.squared, summary(lm7)$sigma))

lm8 <- lm(lpsa ~ 
            lcavol +
            lweight +
            svi +
            lbph +
            age +
            lcp +
            pgg45 +
            gleason, data = prostate)
df24 <- rbind(df24, list(summary(lm8)$adj.r.squared, summary(lm8)$sigma))

```


### It appears the adjusted R-squared and the residual standard error have a perfect linear relationship.

```{r}
# plotting the stored adjusted R-squared and residual standard error from each
# model

df24$vars <- 1:nrow(df24)

ggplot(df24, aes(x = vars, y = residSE)) +
  geom_point()

ggplot(df24, aes(x = vars, y = adjR)) +
  geom_point()

ggplot(df24, aes(x = adjR, y = residSE)) +
  geom_point()
```


## Exercise 2.5
Using the prostate data, plot lpsa against lcavol. Fit the regressions of lpsa
on lcavol and lcavol on lpsa. Display both regression lines on the plot. At
what point do the two lines intersect?


```{r}
lmA <- lm(lcavol ~ lpsa, data = prostate)
lmB <- lm(lpsa ~ lcavol, data = prostate)

ggplot(prostate, aes(lcavol, lpsa)) +
  geom_point() +
  geom_line(aes(x = predict(lmA), color = "lcavol ~ lpsa")) +
  geom_line(aes(y = predict(lmB), color = "lpsa ~ lcavol"))


```



#Linear Models w/ R Chapter 3
## Exercise 3.4

4. Using the sat data:
(a) Fit a model with total sat score as the response and expend, ratio and
salary as predictors. Test the hypothesis that βsalary = 0. Test the hypothesis
that βsalary = βratio = βexpend = 0. Do any of these predictors have an
effect on the response?


```{r}
head(sat)
```


```{r}
# model with 3 predictors
sat_lm1 <- lm(total ~ expend + ratio + salary, data = sat)
summary(sat_lm1)
```

The hypothesis that βsalary = 0 is rejected due to a low p-value of 0.002

```{r}
# test null hypothesis that Beta_salary = 0
# meaning that the salary alone doesn't have any slope/affect on total avg score
sat_lm2 <- lm(total ~ salary, data = sat)
summary(sat_lm2)
```


The null hypothesis that βsalary = βratio = βexpend = 0 is rejected due to the small p-value of 0.0121.

```{r}
# create model where slope = 1 (aka no variables predicting)
sat_nullmod <- lm(total ~ 1, sat)

# compare null to our model created above
anova(sat_nullmod, sat_lm1)
```



(b) Now add takers to the model. Test the hypothesis that βtakers = 0. Compare
this model to the previous one using an F-test. Demonstrate that the F-test and
t-test here are equivalent.

```{r}
# model with 4 predictors
sat_lm3 <- lm(total ~ expend + ratio + salary + takers, data = sat)
summary(sat_lm3)
```


The hypothesis that βtakers = 0 is rejected due to a low p-value of nearly zero.


```{r}
# test null hypothesis that Beta_takers = 0
# meaning that the takers alone doesn't have any slope/affect on total avg score
sat_lm4 <- lm(total ~ takers, data = sat)
summary(sat_lm4)
```

The test shows that the model with the addition of 'takers' is justifiable due to the small p-value.


```{r}
anova(sat_lm1, sat_lm3)
```



#Linear Models w/ R Chapter 4
## Exercise 4.5

5. For the fat data used in this chapter, a smaller model using only age, weight,
height and abdom was proposed on the grounds that these predictors are either
known by the individual or easily measured.

```{r}
fat_lm0 <- lm(brozek ~ age + weight + height + neck + chest + abdom + hip + 
                thigh + knee + ankle + biceps + forearm + wrist, data=fat)
fat_lm1 <- lm(brozek ~ age + weight + height + abdom, data = fat)
```



(a) Compare this model to the full thirteen-predictor model used earlier in the
chapter. Is it justifiable to use the smaller model?  


Since the p-value is small the null hypothesis is rejected. Removing all of the predictors is not justifiable.

We were essentially testing a H0: β's of the removed predictors = 0. They do not equal zero, so we can't remove them (may be better to test one at a time).

```{r}
anova(fat_lm1, fat_lm0)
```



(b) Compute a 95% prediction interval for median predictor values and compare
to the results to the interval for the full model. Do the intervals differ by a
practically important amount?  


Full model is body fat between 9.62% and 25.37%.  

Smaller model is body fat between 9.7% and 25.98%.  
I would argue they do not differ by an practically important amount a user would care about.

```{r}

# grab model and get median coefficients in format the predict func will like
fat_lm0_matrix <- model.matrix(fat_lm0)
(fat_lm0_medians <- apply(fat_lm0_matrix, 2, median))
predict(fat_lm0, new = data.frame(t(fat_lm0_medians)), interval = "prediction")

# and again for the smaller model
fat_lm1_matrix <- model.matrix(fat_lm1)
(fat_lm1_medians <- apply(fat_lm1_matrix, 2, median))
predict(fat_lm1, new = data.frame(t(fat_lm1_medians)), interval = "prediction")

```



(c) For the smaller model, examine all the observations from case numbers 25 to
50. Which two observations seem particularly anomalous?  

Case numbers 47 & 50 have negative body fat %, which isn't possible.

```{r}
new_df_25_50 <- fat[25:50,c(4,5,6,11)]
predict(fat_lm1, new=data.frame(new_df_25_50), interval="prediction")
```




(d) Recompute the 95% prediction interval for median predictor values after these
two anomalous cases have been excluded from the data. Did this make much
difference to the outcome?

The prediction interval is 9.71% to 26.04%. This is a bit smaller than before we removed those 2 troublesome cases.

```{r}
fat_cleaned <- fat[-c(47, 50),]

fat_lm1_cleaned <- lm(brozek ~ age + weight + height + abdom, data = fat_cleaned)

fat_lm1_cleaned_matrix <- model.matrix(fat_lm1_cleaned)
(fat_lm1_cleaned_medians <- apply(fat_lm1_cleaned_matrix, 2, median))
predict(fat_lm1_cleaned, new = data.frame(t(fat_lm1_cleaned_medians)), interval = "prediction")
```



#Linear Models w/ R Chapter 5
## Exercise 5.2  

Use the odor dataset with odor as the response and temp as a predictor. Consider
all possible models that also include all, some or none of the other two predictors.
Report the coefficient for temperature, its standard error, t-statistic and p-value in
each case. Discuss what stays the same, what changes and why. Which model is
best?

```{r}
head(odor)
```


None of the Adjusted R-Squared in the 4 models are all that good, some are even negative. No significant p-values. 

```{r}
odor_lm0 <- lm(odor ~ temp, data = odor)
odor_lm_some <- lm(odor ~ temp + gas, data = odor)
odor_lm_some2 <- lm(odor ~ pack + gas, data = odor)
odor_lm_all <- lm(odor ~ temp + gas + pack, data = odor)

summary(odor_lm0)
summary(odor_lm_some)
summary(odor_lm_some2)
summary(odor_lm_all)

```





#Linear Models w/ R Chapter 14
## Exercise 14.2  

Using the infmort data, find a simple model for the infant mortality in terms of
the other variables. Be alert for transformations and unusual points. Interpret your
model by explaining what the regression parameter estimates mean.

*Note we haven't read the chapter on transformations yet so I may be missing something here*

```{r}
head(infmort)
skim(infmort)

ggplot(infmort, aes(x = income)) +
  geom_histogram()

ggplot(infmort, aes(x = mortality)) +
  geom_histogram()

ggplot(infmort, aes(x = region)) +
  geom_histogram(stat = "count")

ggplot(infmort, aes(x = oil)) +
  geom_histogram(stat = "count")

```
The full model shows income is not significant, but that oil and region might be. 

```{r}
inf_fullmod <- lm(mortality ~ income + oil + region, data = infmort)
summary(inf_fullmod)
```


Checking to see what each one does on it's own, income is once again not significant.

```{r}
drop1(inf_fullmod, test = "F")
```

```{r}
inf_partialmod <- lm(mortality ~ region + oil, data = infmort)
summary(inf_partialmod)
```
Not a ton of improvement. Lets try region and oil as an interaction term.

```{r}
inf_partialmod_int <- lm(mortality ~ region:oil, data = infmort)
summary(inf_partialmod_int)
```

This shows a slightly lower residual standard error, meaning our predictions are better, and the adjusted r-squared increased. 



#Linear Model w/ R Chapter 6
## Exercise 6.1

1. Using the sat dataset, fit a model with the total SAT score as the response and
expend, salary, ratio and takers as predictors. Perform regression diagnostics on
this model to answer the following questions. Display any plots that are relevant.
Do not provide any plots about which you have nothing to say. Suggest possible
improvements or corrections to the model where appropriate.


```{r}
?sat
```

```{r}
sat_model <- lm(total ~ expend + salary + ratio + takers, data = sat)
summary(sat_model)
```



(a) Check the constant variance assumption for the errors.



On the residuals vs fitted plot does appear a bit curved, such that the residuals are more positive on the lower and higher extremes of the x-values. This is slightly concerning so we will look at the square root of the absolute value of the errors, as this effectively doubles the resolution of the residuals to see more clearly.


```{r}
plot(fitted(sat_model), residuals(sat_model), xlab = "Fitted", ylab = "Residuals")
abline(h=0)

```

This appears to have more constant variance and I don't believe there is any reason to be concerned. 

```{r}
plot(fitted(sat_model), sqrt(abs(residuals(sat_model))), xlab = "Fitted", ylab = expression(sqrt(hat(epsilon))))

```



(b) Check the normality assumption.  

There is some flaring toward the highest end of x-values, but otherwise the normality assumption is well-met. 


```{r}
qqnorm(residuals(sat_model), ylab = "Residuals", main = "")
qqline(residuals(sat_model))
```



(c) Check for large leverage points.

A rough rule is that leverages of more than 2p/n should be looked at more closely. In this case that value would be 2 * 4 (predictors) / 50 (n) = 0.16. Looking at the top 10 highest leverage values, the top 7 are larger than this value so we will take a closer look with a half-normal plot (best for positive values).



```{r}
hatv <- hatvalues(sat_model)

head(sort(hatv, decreasing = TRUE), 10)
sum(hatv)
```



We see Utah and California listed as being outliers, but do seem to fall in the trend of the rest of the data despite being very extreme x-values. 


```{r}
states <- row.names(sat)
halfnorm(hatv, labs = states, ylab = "Leverages")
```

Looking at this Q-Q plot of the standardized residuals, things are less concerning. Since the residuals have now been standardized, we expect the points to roughly follow this x = y line, which it does, meaning normality is holding here. Further, we don't have any absolute values beyond 2, which is to be expected under the standard normal.  

**Conclude that there are no leverage points affecting the model's slope.**

```{r}
qqnorm(rstandard(sat_model))
abline(0,1)
```



(d) Check for outliers.  

Using the Bonferroni correction we can compute if a value is a outlier. The general formula is qt(1-alpha/2, n-p).



```{r}
stud <- rstudent(sat_model)
stud[which.max(abs(stud))]

qt(p = 0.05/(50*2), df = 46)

```



(e) Check for influential points.  

An influential point is one whose removal from the dataset would cause a large change in in the fit. The Cook statistics are popular influence diagnostics because they reduce the information to a single value for each case. We see that Utah, West Virginia, and New Hampshire are the top 3 influential observations. 

```{r}
cook <- cooks.distance(sat_model)
halfnorm(cook, 3, labs = states, y.lab = "Cook's distances")
```

To see the model with Utah removed. Compared to our original model, we see the coefficients for expend, salary, and ratio all changed by large magnitudes which is disconcerting that the estimates are so sensitive to just one state. 

```{r}
sat_model_no_utah <- lm(total ~ expend + salary + ratio + takers, data = sat, subset = (cook < max(cook)))
summary(sat_model_no_utah)
summary(sat_model)

```


```{r}
plot(dfbeta(sat_model)[,4], ylab = "Change in ratio coef")
abline(h=0)
### I can't get the identify() function to work to see outliers here
```



(f) Check the structure of the relationship between the predictors and the response.
















